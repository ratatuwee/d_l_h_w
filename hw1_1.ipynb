{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a044eb1-6630-4072-8c52-071df8c6bbd1",
   "metadata": {},
   "source": [
    "# 2021120044_김형겸_hw1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa64c31-82fb-4b30-b793-9b5231641483",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 02_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ba217a-dd92-4190-ad5a-6eb003e74684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74027208-c80c-4959-a758-be2878386345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.Tensor([1, 2, 3], device='cpu')\n",
    "print(t1.dtype)\n",
    "print(t1.device)  \n",
    "print(t1.requires_grad)  \n",
    "print(t1.size())  \n",
    "print(t1.shape)   \n",
    "t1_cpu = t1.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf40a86-8e7a-4231-8348-16edd81453b3",
   "metadata": {},
   "source": [
    "__torch.Tensor == torch.FloatTensor__\n",
    "\n",
    "\n",
    "torch.tensor는 입력 받은 자료형 그대로 tensor화\n",
    "\n",
    "\n",
    "tensor화하면 동일 객체로 사용하는 것이 아닌 새로운객체를 copy해서 tensor화 함\n",
    ">np.array를 torch.as_tensor를 이용할 경우에는 동일 객체를 사용하여 값이 이후에 변경될 수 있다\n",
    "\n",
    "\n",
    "torch.Tensor   \n",
    ">tensor 자료구조 클래스 인스턴스 생성\n",
    "   \n",
    "device='cpu'   \n",
    ">CPU에 배치\n",
    "   \n",
    "t1.dtype   \n",
    ">t1의 데이터 유형\n",
    "  \n",
    "t1.device\n",
    ">t1의 장치 정보\n",
    "\n",
    "t1.size\n",
    ">t1의 크기\n",
    "\n",
    "t1.shape\n",
    ">t1의 모양\n",
    "\n",
    "t1.cpu\n",
    ">t1을 cpu로 복사하여 새로운 tensor 생성 기존 텐서를 다른 장치로 이동하거나 복사할 때 사용\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945f338a-ee07-48d2-980d-247b01a5c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([1, 2, 3], device='cpu')\n",
    "print(t2.dtype)  \n",
    "print(t2.device) \n",
    "print(t2.requires_grad)  \n",
    "print(t2.size())  \n",
    "print(t2.shape)  \n",
    "t2_cpu = t2.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a60d99-8ba6-480e-a9dc-8a47344a0043",
   "metadata": {},
   "source": [
    "torch.tensor\n",
    ">어떠한 데이터를 tensor로 copy 해준다, 데이터가 tensor가 아니면 Tensor클래스를 적용하여 복사\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ec0139-091d-4e07-b16c-f7547e7c2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n",
      "torch.Size([1]) 1\n",
      "torch.Size([5]) 1\n",
      "torch.Size([5, 1]) 2\n",
      "torch.Size([3, 2]) 2\n",
      "torch.Size([3, 2, 1]) 3\n",
      "torch.Size([3, 1, 2, 1]) 4\n",
      "torch.Size([3, 1, 2, 3]) 4\n",
      "torch.Size([3, 1, 2, 3, 1]) 5\n",
      "torch.Size([4, 5]) 2\n",
      "torch.Size([4, 1, 5]) 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 3 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 65\u001b[0m\n\u001b[0;32m     57\u001b[0m a10 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([                 \u001b[38;5;66;03m# shape: torch.Size([4, 1, 5]), ndims(=rank): 3\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]],\n\u001b[0;32m     59\u001b[0m     [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]],\n\u001b[0;32m     60\u001b[0m     [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]],\n\u001b[0;32m     61\u001b[0m     [[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]],\n\u001b[0;32m     62\u001b[0m ])\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(a10\u001b[38;5;241m.\u001b[39mshape, a10\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m---> 65\u001b[0m a11 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# ValueError: expected sequence of length 3 at dim 3 (got 2)\u001b[39;49;00m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 3 at dim 3 (got 2)"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1)\t\t\t     # shape: torch.Size([]), ndims(=rank): 0\n",
    "print(a1.shape, a1.ndim)\n",
    "\n",
    "a2 = torch.tensor([1])\t\t  \t     # shape: torch.Size([1]), ndims(=rank): 1\n",
    "print(a2.shape, a2.ndim)\n",
    "\n",
    "a3 = torch.tensor([1, 2, 3, 4, 5])   # shape: torch.Size([5]), ndims(=rank): 1\n",
    "print(a3.shape, a3.ndim)\n",
    "\n",
    "a4 = torch.tensor([[1], [2], [3], [4], [5]])   # shape: torch.Size([5, 1]), ndims(=rank): 2\n",
    "print(a4.shape, a4.ndim)\n",
    "\n",
    "a5 = torch.tensor([                 # shape: torch.Size([3, 2]), ndims(=rank): 2\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)\n",
    "\n",
    "a6 = torch.tensor([                 # shape: torch.Size([3, 2, 1]), ndims(=rank): 3\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)\n",
    "\n",
    "a7 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 1]), ndims(=rank): 4\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)\n",
    "\n",
    "a8 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3]), ndims(=rank): 4\n",
    "    [[[1, 2, 3], [2, 3, 4]]],\n",
    "    [[[3, 1, 1], [4, 4, 5]]],\n",
    "    [[[5, 6, 2], [6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)\n",
    "\n",
    "\n",
    "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)\n",
    "\n",
    "a10 = torch.tensor([                 # shape: torch.Size([4, 5]), ndims(=rank): 2\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "\n",
    "a10 = torch.tensor([                 # shape: torch.Size([4, 1, 5]), ndims(=rank): 3\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "\n",
    "a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5603e76d-5640-4392-bfb6-e893d172ff32",
   "metadata": {},
   "source": [
    ".ndim\n",
    ">tensor의 깊이\n",
    "\n",
    "\n",
    "마지막 a11처럼 한번의 하나의 값으로 표현 못하게 생성 불가\n",
    "\n",
    "\n",
    "__추가 팁 : shape을 구할 때 좌측 [을 기준으로 하나씩 소거해가며 구하면 쉽게 구할 수 있다__\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4221d32b-f811-485d-a420-bd3d78cbece0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 02_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f82c85d-496e-435f-b756-b90c3bcf745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e9b666-3582-46f7-b681-d051099d9b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "l1 = [1, 2, 3]\n",
    "t1 = torch.Tensor(l1)\n",
    "\n",
    "l2 = [1, 2, 3]\n",
    "t2 = torch.tensor(l2)\n",
    "\n",
    "l3 = [1, 2, 3]\n",
    "t3 = torch.as_tensor(l3)\n",
    "\n",
    "l1[0] = 100\n",
    "l2[0] = 100\n",
    "l3[0] = 100\n",
    "\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0348762d-6798-4495-bed1-370442f4f306",
   "metadata": {},
   "source": [
    "torch.Tensor\n",
    ">int 입력 시 float로 변환\n",
    ">\n",
    ">\n",
    ">Tensor 객체로 입력 받은 메모리 공간을 그대로 사용\n",
    ">\n",
    ">\n",
    ">list나 numpy로 입력 받은 값을 복사하여 Tensor 객체 생성\n",
    "\n",
    "torch.tensor\n",
    ">int 입력 시 int 그대로\n",
    ">\n",
    ">\n",
    ">입력 받은 데이터를 새로운 메모리 공간에 복사해 Tensor 객체 생성\n",
    "\n",
    "torch.as_tensor\n",
    ">default값으로 데이터 유형 및 장치 설정 유지\n",
    ">\n",
    ">\n",
    ">list일 때 값 복사해서 사용\n",
    "\n",
    "\n",
    "위 3가지 방법 모두 기존 값을 그대로 사용하는 것이 아닌 새로운 값이라는 것을 알 수 있다\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b937bb6-7aef-4ae8-bf4b-2ed498ae59e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([100,   2,   3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "l4 = np.array([1, 2, 3])\n",
    "t4 = torch.Tensor(l4)\n",
    "\n",
    "l5 = np.array([1, 2, 3])\n",
    "t5 = torch.tensor(l5)\n",
    "\n",
    "l6 = np.array([1, 2, 3])\n",
    "t6 = torch.as_tensor(l6)\n",
    "\n",
    "l4[0] = 100\n",
    "l5[0] = 100\n",
    "l6[0] = 100\n",
    "\n",
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38514258-03f1-4b40-824c-008e66ef1fa0",
   "metadata": {},
   "source": [
    "torch.as_tensor\n",
    ">array일 때 값을 복사하지 않고 그대로 사용\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064cf96-3d5d-4c4b-949d-aece6661ec9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b88190-808a-4340-a6fe-c7e62e8feac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e41c9520-07d0-430b-b724-820c96107bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(5,))  \n",
    "t1_like = torch.ones_like(input=t1)\n",
    "print(t1)  \n",
    "print(t1_like) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579344a-d764-476c-ac9d-7aa99098f476",
   "metadata": {},
   "source": [
    "torch.ones(size=(5,))\n",
    "torch.ones(5)\n",
    ">요소가 1인 사이즈가 5인 tensor 생성\n",
    "\n",
    "torch.ones_like(input=t1)\n",
    ">주어진 입력 tensor와 동일한 모양 및 데이터 유형을 가지지만 모든 요소가 1인 tensor 생성\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e40c03-f273-493c-af0f-e9f1e259d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.zeros(size=(6,)) \n",
    "t2_like = torch.zeros_like(input=t2)\n",
    "print(t2)  \n",
    "print(t2_like) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe8cee-f6d8-4bf0-90e2-f74a8f42b50f",
   "metadata": {},
   "source": [
    "torch.zeros(size=(6,))\n",
    "torch.zeros(6)\n",
    ">요소가 0인 사이즈가 6인 tensor 생성\n",
    "\n",
    "torch.zeros_like(input=t2)\n",
    ">주어진 입력 tensor와 동일한 모양 및 데이터 유형을 가지지만 모든 요소가 0인 tensor 생성\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "224816aa-3588-444d-996b-d6028bc5d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.empty(size=(4,))  \n",
    "t3_like = torch.empty_like(input=t3)\n",
    "print(t3)  \n",
    "print(t3_like)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a944c-9ffa-4e72-bdf6-a113cef0dd8f",
   "metadata": {},
   "source": [
    "torch.empty(size=(4,))\n",
    "\n",
    ">초기화 되지 않은 size 4의 tensor 반환\n",
    "\n",
    "torch.empty_like(input=t3)\n",
    ">input과 같은크기의 초기화되지 않은 텐서 반환\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d3ae8c-3564-4e01-a3b2-61a3ba7e2ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.eye(n=3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74487216-2476-430d-864c-6fc5c0917b64",
   "metadata": {},
   "source": [
    "torch.eye(n=3)\n",
    ">[n,n]짜리 단위 행렬 생성\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579ae98-11ab-44b9-9f54-fa9bf1a61dcc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a88e1837-0d0e-4871-bd3f-37ae1515cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a8173f-685d-4ee6-b353-5da8fde7171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15, 13]])\n",
      "tensor([[0.6162, 0.3214, 0.4610]])\n",
      "tensor([[-0.4597, -0.1294, -0.8072]])\n",
      "tensor([[ 9.9249, 10.2503],\n",
      "        [ 9.7428,  9.6079],\n",
      "        [10.5029,  8.6182]])\n",
      "tensor([0.0000, 2.5000, 5.0000])\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randint(low=10, high=20, size=(1, 2))\n",
    "print(t1)\n",
    "\n",
    "t2 = torch.rand(size=(1, 3))\n",
    "print(t2)\n",
    "\n",
    "t3 = torch.randn(size=(1, 3))\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.normal(mean=10.0, std=1.0, size=(3, 2))\n",
    "print(t4)\n",
    "\n",
    "t5 = torch.linspace(start=0.0, end=5.0, steps=3)\n",
    "print(t5)\n",
    "\n",
    "t6 = torch.arange(5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57fcaf-0011-42d9-ae34-8fc38d2074cb",
   "metadata": {},
   "source": [
    "torch.randint(low=10, high=20, size=(1, 2))\n",
    ">[10, 20)의 요소를 가지는 [1, 2] tensor 생성\n",
    ">\n",
    ">\n",
    ">torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\n",
    "t2 = torch.rand(size=(1, 3))\n",
    ">[0, 1)의 요소를 가지는 [1, 3] tensor 생성\n",
    ">\n",
    ">\n",
    ">torch.rand(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\n",
    "torch.randn(size=(1, 3))\n",
    ">평균 0, 분산 1의 정규 분포에서 요소를 가지는 [1, 3] tensor 생성\n",
    ">\n",
    ">\n",
    ">torch.randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\n",
    "t4 = torch.normal(mean=10.0, std=1.0, size=(3, 2))\n",
    ">10의 평균을 가지는 1의 표준편차에서 요소를 가지는 [3, 2] tensor 생성\n",
    ">\n",
    ">\n",
    ">torch.normal(mean, std, *, generator=None, out=None)\n",
    "\n",
    "t5 = torch.linspace(start=0.0, end=5.0, steps=3)\n",
    ">0부터 5까지의 균등한 간격을 가지는 3개의 요소를 가지는 tensor 생성\n",
    ">\n",
    ">\n",
    ">torch.linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\n",
    "t6 = torch.arange(5)\n",
    ">[0, 5)에서 1의 간격을 가지는 tensor 생성\n",
    ">\n",
    ">\n",
    ">torch.arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00acdde4-2c49-45d0-a9dd-da01e9c018f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "print()\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3071bc-ad29-4e9b-8254-de5d4df6f9a6",
   "metadata": {},
   "source": [
    "torch.manual_seed(1729)\n",
    ">난수 생성을 위한 시드 설정\n",
    ">\n",
    ">\n",
    ">torch.Generator 객체 반환\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb4617-e4b7-4e44-9ff6-9ed026ba7baa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df8ca78c-98ff-4363-a1e6-aa7d0ad9aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc0c2450-10ae-4cd2-8cf7-83a603d2e9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[18.0429,  7.2532, 19.6519],\n",
      "        [10.8626,  2.1505, 19.6913]], dtype=torch.float64)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3))\n",
    "print(a.dtype)\n",
    "\n",
    "b = torch.ones((2, 3), dtype=torch.int16)\n",
    "print(b)\n",
    "\n",
    "c = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
    "print(c)\n",
    "\n",
    "d = b.to(torch.int32)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a85d4c-ac90-47ee-8cdd-da7ae087d0ba",
   "metadata": {},
   "source": [
    "torch.ones((2, 3))\n",
    ">ones default dtype = float32\n",
    "\n",
    "torch.ones((2, 3), dtype=torch.int16)\n",
    ">dtype int16 ones\n",
    "\n",
    "torch.rand((2, 3), dtype=torch.float64) * 20.\n",
    ">dtype float64 rand 값에 *20.\n",
    "\n",
    "b.to(torch.int32)\n",
    ">b tensor int32로 생성\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aff8444-8fa3-483b-95fe-a6ec9d570463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int16\n",
      "torch.float64\n",
      "torch.int16\n",
      "torch.float64\n",
      "torch.int16\n",
      "torch.float64\n",
      "torch.int16\n"
     ]
    }
   ],
   "source": [
    "double_d = torch.ones(10, 2, dtype=torch.double)\n",
    "short_e = torch.tensor([[1, 2]], dtype=torch.short)\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)\n",
    "\n",
    "double_d = torch.zeros(10, 2).double()\n",
    "short_e = torch.ones(10, 2).short()\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)\n",
    "\n",
    "double_d = torch.zeros(10, 2).to(torch.double)\n",
    "short_e = torch.ones(10, 2).to(dtype=torch.short)\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)\n",
    "\n",
    "double_d = torch.zeros(10, 2).type(torch.double)\n",
    "short_e = torch.ones(10, 2). type(dtype=torch.short)\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7be821-f64f-4e4e-9a97-f26334d14136",
   "metadata": {},
   "source": [
    "torch.ones(10, 2, dtype=torch.double)\n",
    "torch.zeros(10, 2).double()\n",
    "torch.zeros(10, 2).to(torch.double)\n",
    "torch.zeros(10, 2).type(torch.double)\n",
    ">dtype = float64(double)\n",
    "\n",
    "torch.tensor([[1, 2]], dtype=torch.short)\n",
    "torch.ones(10, 2).short()\n",
    "torch.ones(10, 2).to(dtype=torch.short)\n",
    "torch.ones(10, 2). type(dtype=torch.short)\n",
    ">dtype = int16(short)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0304590-220e-494f-a1a9-80ce8d03b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "double_f = torch.rand(5, dtype=torch.double)\n",
    "short_g = double_f.to(torch.short)\n",
    "print((double_f * short_g).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f106b2c-13b4-4301-bd5a-71220bb973c7",
   "metadata": {},
   "source": [
    "__다른 언어와 마찬가지로 바이트가 큰 크기에 타입에 맞추어짐__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9764ad-4d0d-4ea1-9399-01aa2cfb0fd6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a6e1e5-a354-4783-8547-52861d466e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb143d70-e7ca-4ab3-9a58-c02afcdd143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(2, 3))\n",
    "t2 = torch.ones(size=(2, 3))\n",
    "t3 = torch.add(t1, t2)\n",
    "t4 = t1 + t2\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b6d5f-0207-49eb-aba3-2e4ebccf66f8",
   "metadata": {},
   "source": [
    "torch.add(t1, t2), t1 + t2\n",
    ">shape이 같음, 각각의 위치끼리 값 더해 tensor 생성\n",
    ">\n",
    ">\n",
    ">torch.add(input, other, *, out=None)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cabb19f4-fde8-4010-8073-d276982c97f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.sub(t1, t2)\n",
    "t6 = t1 - t2\n",
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98658fa0-81d4-4b99-a655-5cec7794c23f",
   "metadata": {},
   "source": [
    "torch.sub(t1, t2), t1 - t2\n",
    ">shape이 같음, 각각의 위치에서 t1의 요소에서 t2의 요소를 뻄\n",
    ">\n",
    ">\n",
    ">torch.sub(input, other, *, alpha=1, out=None)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b644a59a-9537-4fa0-ad75-d047b60a0b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.mul(t1, t2)\n",
    "t8 = t1 * t2\n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d47af3a-2791-4c27-851f-d197a07809b3",
   "metadata": {},
   "source": [
    "torch.mul(t1, t2), t1 * t2\n",
    ">shape이 같음, 각각의 위치에서 값을 곱해 tensor 생성\n",
    ">\n",
    ">\n",
    ">torch.mul(input, other, *, out=None)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a77c9ff5-496a-4441-ab49-3e1b0f3cbdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.div(t1, t2)\n",
    "t10 = t1 / t2\n",
    "print(t9)\n",
    "print(t10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c108982d-864f-4b9b-8f48-1f0ba951c115",
   "metadata": {},
   "source": [
    "torch.div(t1, t2), t1 / t2\n",
    ">shape이 같음, 각각의 위치에서 t1의 요소에서 t2의 요소를 나눔\n",
    ">\n",
    ">\n",
    ">torch.div(input, other, *, rounding_mode=None, out=None)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73521d71-89fb-4834-ae0d-11a2f5ed496b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63cd5ba-791d-4b76-85c5-514293f8a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a614079d-200e-4b69-ad5d-0e93e2320da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) torch.Size([])\n",
      "tensor([[0.1329, 1.9337],\n",
      "        [0.9776, 1.2158]]) torch.Size([2, 2])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.dot(\n",
    "  torch.tensor([2, 3]), torch.tensor([2, 1])\n",
    ")\n",
    "print(t1, t1.size())\n",
    "\n",
    "t2 = torch.randn(2, 3)\n",
    "t3 = torch.randn(3, 2)\n",
    "t4 = torch.mm(t2, t3)\n",
    "print(t4, t4.size())\n",
    "\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(10, 4, 5)\n",
    "t7 = torch.bmm(t5, t6)\n",
    "print(t7.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a31c12-7d25-4ac3-bcae-dfca9183b0a4",
   "metadata": {},
   "source": [
    "torch.dot\n",
    ">두 텐서의 도트 곱을 계산하는데 사용, 요소 수가 같은 두 개의 1D 텐서의 도트 곱만 계산 가능\n",
    ">\n",
    ">\n",
    ">torch.dot(input, other, *, out=None)\n",
    "\n",
    "torch.mm(t2, t3)\n",
    ">t2, t3의 행렬 곱셈 수행\n",
    ">\n",
    ">\n",
    ">torch.mm(input, mat2, *, out=None)\n",
    ">\n",
    ">\n",
    ">input(n*m), mat2(m*p), oup(n*p)\n",
    "\n",
    "torch.bmm(t5, t6)\n",
    ">b개의 행렬 곱셈 수행\n",
    ">\n",
    ">\n",
    ">torch.bmm(input, mat2, *, deterministic=False, out=None)\n",
    ">\n",
    ">\n",
    ">input(b*n*m), mat2(b*m*p), oup(b*n*p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea1fbe-8c92-4867-8053-cf537cbe3326",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fff714c-487f-4651-b71f-22e2a0b5d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3399, -1.4125,  1.1066])\n",
      "tensor([ 1.8106, -1.3298, -1.5758])\n",
      "tensor(-0.4808)\n",
      "torch.Size([]) !\n",
      "tensor([[-0.3648, -0.2919, -0.2613, -0.5564],\n",
      "        [-1.5579,  0.6375, -0.7622,  1.3913],\n",
      "        [ 0.9190,  0.0926,  0.7709,  0.3425]])\n",
      "tensor([ 0.1820, -0.7398,  0.6576,  0.5444])\n",
      "tensor([-0.3252, -0.4989,  0.7921])\n",
      "torch.Size([3]) !!\n",
      "tensor([ 0.0423,  0.6298, -0.6318])\n",
      "tensor([-1.5772,  0.3306, -0.9781,  0.6362])\n",
      "torch.Size([4]) !!\n",
      "tensor([[[ 0.9046, -1.3521,  0.7784,  0.0410],\n",
      "         [ 0.2024, -1.7127,  0.3070, -0.6011],\n",
      "         [ 0.7466, -0.5190, -1.0383,  2.0450]],\n",
      "\n",
      "        [[-0.2236,  0.8599, -2.3212, -0.1385],\n",
      "         [ 0.8465,  0.5619, -0.0510, -1.3666],\n",
      "         [ 0.3746, -1.6600, -0.4449,  0.9988]],\n",
      "\n",
      "        [[-0.6811, -0.9588,  1.0690,  0.6095],\n",
      "         [-0.6558,  0.4717, -0.3714, -0.3376],\n",
      "         [ 0.4453, -0.8635,  1.0695,  0.5943]],\n",
      "\n",
      "        [[-1.9282, -0.0222, -1.0411,  1.1112],\n",
      "         [-0.0609,  0.9552, -0.3780,  0.2547],\n",
      "         [-1.0540,  0.2499, -0.0312, -1.1924]],\n",
      "\n",
      "        [[-1.5224, -0.8705,  0.1258,  0.1559],\n",
      "         [-2.9435, -0.1228,  0.2863,  0.9173],\n",
      "         [ 0.0310,  0.3576,  1.5742, -0.3671]],\n",
      "\n",
      "        [[-0.8644,  0.5749, -1.8019,  0.8948],\n",
      "         [-0.8407,  0.2245, -0.4844,  2.0536],\n",
      "         [ 0.2129,  0.7541,  1.0708,  1.7159]],\n",
      "\n",
      "        [[ 0.2175,  0.6531, -0.8491,  1.1856],\n",
      "         [-0.2080, -0.5535,  1.2210,  0.3283],\n",
      "         [ 0.9644,  0.4702,  0.4217, -1.1734]],\n",
      "\n",
      "        [[ 1.6127, -0.6559,  0.4705, -0.9319],\n",
      "         [-0.2222, -1.1312,  0.8910,  1.0009],\n",
      "         [-1.8462, -1.3211,  0.1073,  0.2559]],\n",
      "\n",
      "        [[ 0.0496,  1.0375,  0.9761, -0.3007],\n",
      "         [-1.0314, -0.9965, -1.4271,  0.3620],\n",
      "         [-0.4591, -0.5469,  0.2089,  2.1635]],\n",
      "\n",
      "        [[ 0.3517, -0.7739, -2.5685, -0.1392],\n",
      "         [-0.6379, -0.3386, -1.2807,  1.9571],\n",
      "         [ 1.3167,  0.2513,  0.4674, -0.4318]]])\n",
      "tensor([0.5563, 0.4740, 0.5535, 0.2334])\n",
      "tensor([[ 0.3028, -0.6696,  0.0720],\n",
      "        [-1.0339,  0.3900, -0.5916],\n",
      "        [-0.0994, -0.4256,  0.5691],\n",
      "        [-1.4002,  0.2691, -0.7635],\n",
      "        [-1.1535, -1.3232,  0.9724],\n",
      "        [-0.9969, -0.1500,  1.4692],\n",
      "        [ 0.2374,  0.3744,  0.7189],\n",
      "        [ 0.6292,  0.0670, -1.5342],\n",
      "        [ 0.9895, -1.7516,  0.1060],\n",
      "        [-1.6255, -0.7675,  1.0096]])\n",
      "torch.Size([10, 3]) !!!\n",
      "tensor([[[-0.9589, -0.1418, -0.2527, -1.5144],\n",
      "         [-0.9105, -0.0178,  1.0304,  0.1418],\n",
      "         [-3.1007, -1.2110, -0.0609,  0.6712]],\n",
      "\n",
      "        [[-0.5535,  1.2662, -0.4404, -0.5488],\n",
      "         [ 1.5066,  0.5141,  0.2666,  1.2093],\n",
      "         [-0.7926,  0.4498,  0.7114, -0.7635]],\n",
      "\n",
      "        [[ 1.7963,  0.5264,  0.3547,  1.2583],\n",
      "         [-1.2178,  1.3499,  2.3255,  0.1357],\n",
      "         [-0.0130,  0.3771, -2.1396,  0.5770]],\n",
      "\n",
      "        [[ 0.2479, -0.7362,  1.3973,  0.2609],\n",
      "         [ 0.4884, -0.0801, -0.2990, -0.3169],\n",
      "         [ 1.4243, -0.3743, -0.6222,  0.3412]],\n",
      "\n",
      "        [[ 1.6277,  0.7473, -0.1968,  0.3402],\n",
      "         [ 1.3009,  0.6680,  0.5611, -0.8485],\n",
      "         [ 0.4951,  0.0212,  0.3768, -0.3505]],\n",
      "\n",
      "        [[ 0.2361, -0.7422, -1.2833,  0.7083],\n",
      "         [ 0.4709, -1.3356,  0.6438,  2.3591],\n",
      "         [ 0.3003, -0.4286,  0.3567, -0.9349]],\n",
      "\n",
      "        [[-1.7957, -0.4269,  2.9896, -0.7369],\n",
      "         [ 0.7490,  0.4214,  0.4496, -0.6855],\n",
      "         [-1.7773, -0.1322, -0.4668,  0.0657]],\n",
      "\n",
      "        [[ 0.2363,  1.0790, -1.5648, -1.3494],\n",
      "         [-0.4267,  1.7307,  0.0884, -2.8603],\n",
      "         [ 1.2885, -0.4992,  2.3207, -2.9480]],\n",
      "\n",
      "        [[-1.6180, -0.5319, -0.0667, -1.5756],\n",
      "         [-2.1628,  0.5509, -0.0040,  1.3279],\n",
      "         [-0.4557,  0.1793,  1.6901, -0.4288]],\n",
      "\n",
      "        [[-2.0162,  1.4051, -2.0604,  0.0461],\n",
      "         [ 1.7902, -0.9044, -0.2813,  0.7205],\n",
      "         [-0.7804,  0.0612, -0.9484, -0.2961]]])\n",
      "tensor([[[ 4.2137e-01,  6.7062e-01,  1.1554e-01, -6.1154e-02,  6.5270e-02],\n",
      "         [ 1.2197e-01, -5.6692e-02, -1.5449e-01,  4.3426e-01,  7.2096e-01],\n",
      "         [ 1.1367e-01,  4.4061e-02, -8.1807e-01, -7.0402e-02, -1.1794e+00],\n",
      "         [ 1.0165e+00, -9.6297e-01, -4.9728e-01,  6.4855e-01, -2.3167e+00]],\n",
      "\n",
      "        [[-1.6510e+00,  2.7796e-01, -5.9217e-01, -1.4966e-01, -7.5182e-01],\n",
      "         [-1.6611e-01,  2.5366e+00, -7.4139e-01,  4.3045e-01, -7.4488e-01],\n",
      "         [-2.4970e+00, -1.2713e+00, -7.1162e-01,  1.6450e-01, -7.8618e-01],\n",
      "         [ 1.0630e+00,  4.1500e-03, -2.3304e+00, -7.9558e-02, -4.6886e-01]],\n",
      "\n",
      "        [[-4.7504e-01, -1.4898e+00, -5.6051e-01,  5.9474e-01,  4.3902e-01],\n",
      "         [-1.2736e-01,  1.9034e+00,  8.1374e-01,  8.2720e-01,  1.2588e+00],\n",
      "         [ 6.2326e-01,  1.5055e+00, -9.7583e-01, -3.8410e-01,  4.7373e-01],\n",
      "         [-8.8282e-01, -6.8965e-01,  2.8538e-01,  7.5738e-01, -4.8892e-01]],\n",
      "\n",
      "        [[ 9.9615e-01, -1.4466e-01,  6.1216e-01, -1.4934e+00,  3.6874e-01],\n",
      "         [ 1.2678e+00, -1.3565e+00,  1.3808e+00, -9.7378e-01,  9.0821e-04],\n",
      "         [-2.2156e+00, -5.4618e-01, -1.1312e+00,  6.0100e-01,  1.0560e-01],\n",
      "         [ 5.0373e-01,  1.2690e+00,  1.5055e+00,  2.6278e-03, -9.1296e-01]],\n",
      "\n",
      "        [[-6.9749e-02,  1.1148e+00, -9.6965e-01, -1.3298e+00,  6.9744e-01],\n",
      "         [ 8.7949e-01, -8.1858e-02, -6.5830e-01, -1.4159e+00, -5.4031e-01],\n",
      "         [ 2.4096e+00,  2.2960e+00, -1.3801e+00,  1.5391e+00,  2.1528e-01],\n",
      "         [ 2.6556e-01,  6.2586e-01, -2.1616e+00, -1.3752e+00,  3.3091e-02]],\n",
      "\n",
      "        [[-5.9285e-01, -5.0411e-01, -4.2201e-01, -1.2156e+00, -1.8739e-01],\n",
      "         [ 3.3913e-02,  1.0465e+00, -1.7319e+00,  6.0958e-02, -1.3287e+00],\n",
      "         [-1.4229e+00,  1.6905e-01,  6.1121e-01, -4.8283e-01,  7.9429e-01],\n",
      "         [-1.6736e+00, -1.0058e-01, -7.1072e-01,  7.3213e-01,  6.8414e-01]],\n",
      "\n",
      "        [[-1.3706e+00,  1.1791e+00,  1.3687e+00,  1.4552e+00,  5.0922e-01],\n",
      "         [-1.0914e+00, -1.6944e+00, -1.4755e-02, -8.9014e-01, -2.1520e-01],\n",
      "         [ 1.4194e+00, -2.1860e-01, -5.9113e-02, -1.2821e+00, -8.6991e-01],\n",
      "         [-1.4782e+00,  4.2489e-01, -3.8923e-01, -3.8306e-01, -6.4720e-01]],\n",
      "\n",
      "        [[-2.6316e-01, -2.4025e-01, -1.2183e+00, -8.5720e-01, -9.8095e-02],\n",
      "         [ 3.7771e-01,  3.3742e-01,  4.6464e-01,  2.7980e-01,  5.2402e-01],\n",
      "         [-1.7903e+00,  3.1627e+00, -5.5743e-01,  5.1135e-01,  6.8615e-02],\n",
      "         [-8.9176e-01, -1.2801e+00, -1.8511e-01,  6.0019e-01, -2.4697e-01]],\n",
      "\n",
      "        [[-1.0310e+00,  8.6630e-01, -1.4590e-01,  2.4669e-01, -8.2081e-01],\n",
      "         [-1.3159e+00,  1.0018e+00, -6.4321e-01, -1.5636e+00, -2.4980e-01],\n",
      "         [-8.9784e-01,  9.5611e-01, -3.1868e-01,  1.2310e+00,  4.9746e-01],\n",
      "         [-7.6195e-01, -4.6940e-01, -1.9798e-02, -3.7409e-01, -1.1085e+00]],\n",
      "\n",
      "        [[-1.7454e-01,  1.8719e+00,  3.5474e-01, -8.6046e-01,  8.0422e-01],\n",
      "         [ 5.9544e-01,  2.2274e-01,  2.1315e+00, -5.6083e-01,  1.4224e-01],\n",
      "         [-2.1791e+00, -1.1467e+00,  1.4169e+00, -9.9280e-01, -4.8678e-01],\n",
      "         [ 1.3357e+00, -1.2262e+00,  9.9547e-01, -2.5153e-01,  1.4719e+00]]])\n",
      "tensor([[[-1.9895e+00,  8.1214e-01,  8.7093e-01, -9.6732e-01,  3.6416e+00],\n",
      "         [-1.2459e-01, -7.0072e-01, -1.0159e+00,  6.7342e-02, -1.6160e+00],\n",
      "         [-7.7884e-01, -2.6598e+00, -4.5516e-01,  1.0335e-01, -2.5587e+00]],\n",
      "\n",
      "        [[ 1.2198e+00,  3.6155e+00,  9.8131e-01,  5.9910e-01,  7.6505e-02],\n",
      "         [-1.9532e+00,  1.3889e+00, -4.2812e+00, -5.6518e-02, -2.2923e+00],\n",
      "         [-1.3542e+00,  1.3077e-02,  1.4087e+00,  4.9001e-01,  5.9416e-02]],\n",
      "\n",
      "        [[-1.8101e+00, -2.0080e+00, -5.6554e-01,  2.3205e+00,  1.0040e+00],\n",
      "         [ 1.7361e+00,  7.7910e+00, -4.4955e-01, -3.9805e-01,  2.1999e+00],\n",
      "         [-1.8847e+00, -2.8818e+00,  2.5666e+00,  1.5630e+00, -8.2667e-01]],\n",
      "\n",
      "        [[-3.6507e+00,  5.3084e-01, -2.0525e+00,  1.1871e+00,  7.1496e-05],\n",
      "         [ 8.8775e-01, -2.0081e-01,  4.9548e-02, -8.3191e-01,  4.3773e-01],\n",
      "         [ 2.4948e+00,  1.0745e+00,  1.5726e+00, -2.1357e+00,  1.4765e-01]],\n",
      "\n",
      "        [[ 1.5999e-01,  1.5146e+00, -2.5341e+00, -3.9933e+00,  7.0034e-01],\n",
      "         [ 1.6235e+00,  2.1529e+00, -6.4144e-01, -6.4529e-01,  6.3907e-01],\n",
      "         [ 7.9889e-01,  1.1960e+00, -2.5642e-01,  3.7352e-01,  4.0337e-01]],\n",
      "\n",
      "        [[ 4.7556e-01, -1.1840e+00, -1.0196e-01,  8.0594e-01,  4.0721e-01],\n",
      "         [-5.1887e+00, -1.7635e+00,  8.3127e-01,  7.6251e-01,  3.8117e+00],\n",
      "         [ 8.6447e-01, -4.4555e-01,  1.4980e+00, -1.2478e+00,  1.5692e-01]],\n",
      "\n",
      "        [[ 8.2598e+00, -2.3606e+00, -2.3413e+00, -5.7838e+00, -2.9463e+00],\n",
      "         [ 1.6489e-01, -2.2029e-01,  1.2592e+00,  4.0104e-01,  3.4328e-01],\n",
      "         [ 1.8205e+00, -1.7417e+00, -2.4286e+00, -1.8953e+00, -5.1306e-01]],\n",
      "\n",
      "        [[ 4.3502e+00, -2.9144e+00,  1.3355e+00, -1.5107e+00,  7.6810e-01],\n",
      "         [ 3.1584e+00,  4.6276e+00,  1.8042e+00, -8.2149e-01,  1.6613e+00],\n",
      "         [-2.0536e+00,  1.0635e+01, -2.5497e+00, -1.8269e+00,  4.9934e-01]],\n",
      "\n",
      "        [[ 3.6286e+00, -1.2587e+00,  6.3062e-01,  9.3986e-01,  3.1744e+00],\n",
      "         [ 4.9680e-01, -1.9489e+00, -6.3812e-02, -1.8967e+00,  1.6363e-01],\n",
      "         [-9.5690e-01,  1.6021e+00, -5.7897e-01,  1.8481e+00,  1.6453e+00]],\n",
      "\n",
      "        [[ 5.7398e+00, -1.1550e+00, -5.9374e-01,  2.9808e+00, -3.5078e-01],\n",
      "         [ 7.2429e-01,  2.5887e+00, -9.7392e-01, -9.3521e-01,  2.5085e+00],\n",
      "         [ 1.8439e+00,  3.4610e-03, -1.7849e+00,  1.6532e+00, -5.9298e-01]]])\n",
      "torch.Size([10, 3, 5]) !!!!\n",
      "tensor([[[ 1.0488,  0.3733,  0.8150,  1.3882],\n",
      "         [-0.0880,  1.0491, -0.3219,  1.2992],\n",
      "         [-0.8768, -0.2477,  1.0649, -0.0159]],\n",
      "\n",
      "        [[ 1.3479,  1.3607,  0.6281, -0.8888],\n",
      "         [-1.6481,  0.7769,  0.5156,  0.0909],\n",
      "         [-0.3012, -0.7543, -0.1966, -0.0925]],\n",
      "\n",
      "        [[ 0.1417,  1.5705, -0.4705,  0.4433],\n",
      "         [-0.0559,  2.8998,  1.0736, -0.1887],\n",
      "         [-1.1217, -1.0647,  0.0938,  0.1884]],\n",
      "\n",
      "        [[ 0.5693, -0.4253, -1.3343, -0.5146],\n",
      "         [-1.9083, -1.3123,  0.4662,  1.3519],\n",
      "         [-0.6550, -0.0739, -0.2706, -1.0169]],\n",
      "\n",
      "        [[ 0.1764, -2.0244, -1.2764,  0.3731],\n",
      "         [-0.8258, -0.3880,  0.3906,  0.6219],\n",
      "         [-0.6389,  2.1225, -0.7103,  1.0961]],\n",
      "\n",
      "        [[-1.4949, -2.6237,  1.0910, -0.1300],\n",
      "         [-0.8262, -0.5678, -1.3344, -0.8437],\n",
      "         [-2.0115,  0.3617, -0.7426, -1.6488]],\n",
      "\n",
      "        [[-0.8207, -1.0355,  0.3637,  0.4308],\n",
      "         [ 0.2499, -1.1650,  0.7407,  1.3215],\n",
      "         [ 0.1266, -1.0969,  0.3675,  0.1579]],\n",
      "\n",
      "        [[-1.5635, -1.2557,  1.5932,  0.5891],\n",
      "         [ 0.8000, -0.6810,  0.0449, -1.1506],\n",
      "         [ 0.8014, -1.3391,  0.7826,  2.2886]],\n",
      "\n",
      "        [[-0.6389,  1.1827,  0.9955,  1.7992],\n",
      "         [-1.2869, -0.5956,  0.4228,  1.0581],\n",
      "         [-1.0091, -1.3689, -0.8704, -0.3102]],\n",
      "\n",
      "        [[-0.3776, -0.3751,  1.6527,  0.7610],\n",
      "         [-0.4301, -0.4200,  0.3066,  0.0209],\n",
      "         [ 0.2442, -0.2512,  0.5746, -0.6868]]])\n",
      "tensor([[-0.0808,  2.2012,  0.6778, -0.2725, -1.4346],\n",
      "        [-0.0098, -0.7541, -1.0162,  0.0622,  0.3438],\n",
      "        [-0.7797,  1.3568, -1.7913, -1.9599, -0.8314],\n",
      "        [-0.8718,  2.6067, -1.2176, -0.3057, -0.1332]])\n",
      "tensor([[[-1.9341e+00,  6.7515e+00, -2.8187e+00, -2.2843e+00, -2.2388e+00],\n",
      "         [-8.8475e-01,  1.9649e+00, -2.1309e+00,  3.2299e-01,  5.8165e-01],\n",
      "         [-7.4325e-01, -3.3969e-01, -2.2309e+00, -1.8587e+00,  2.8940e-01]],\n",
      "\n",
      "        [[ 1.6292e-01,  4.7628e-01, -5.1221e-01, -1.2420e+00, -1.8697e+00],\n",
      "         [-3.5561e-01, -3.2773e+00, -2.9407e+00, -5.4083e-01,  2.1908e+00],\n",
      "         [ 2.6562e-01, -6.0205e-01,  1.0271e+00,  4.4876e-01,  3.4853e-01]],\n",
      "\n",
      "        [[-4.6351e-02, -3.5521e-01, -1.1967e+00,  8.4573e-01,  6.6888e-01],\n",
      "         [-6.9633e-01, -1.3449e+00, -4.6779e+00, -1.8508e+00,  2.0978e-01],\n",
      "         [-1.3642e-01, -1.0477e+00, -7.5781e-02, -2.0811e-03,  1.1400e+00]],\n",
      "\n",
      "        [[ 1.4471e+00, -1.5778e+00,  3.8347e+00,  2.5908e+00,  2.1493e-01],\n",
      "         [-1.3752e+00,  9.4548e-01, -2.4412e+00, -8.8875e-01,  1.7188e+00],\n",
      "         [ 1.1512e+00, -4.4039e+00,  1.3541e+00,  1.0151e+00,  1.2746e+00]],\n",
      "\n",
      "        [[ 6.7549e-01,  1.1555e+00,  4.0090e+00,  2.2136e+00,  6.2342e-02],\n",
      "         [-7.7623e-01,  6.2580e-01, -1.6224e+00, -7.5485e-01,  6.4371e-01],\n",
      "         [-3.7078e-01, -1.1135e+00, -2.6520e+00,  1.3631e+00,  2.0909e+00]],\n",
      "\n",
      "        [[-5.9090e-01, -1.7099e-01, -1.4299e-01, -1.8542e+00,  3.5280e-01],\n",
      "         [ 1.8483e+00, -5.4003e+00,  3.4346e+00,  3.0630e+00,  2.2119e+00],\n",
      "         [ 2.1754e+00, -1.0006e+01,  1.6068e+00,  2.5300e+00,  3.8471e+00]],\n",
      "\n",
      "        [[-5.8269e-01,  5.9063e-01, -6.7989e-01, -6.8521e-01,  4.6157e-01],\n",
      "         [-1.7384e+00,  5.8781e+00, -1.5825e+00, -1.9961e+00, -1.5509e+00],\n",
      "         [-4.2371e-01,  2.0159e+00,  3.4995e-01, -8.7125e-01, -8.8537e-01]],\n",
      "\n",
      "        [[-1.6173e+00,  1.2026e+00, -3.3549e+00, -2.9547e+00,  4.0814e-01],\n",
      "         [ 9.1009e-01, -6.6399e-01,  2.5547e+00,  3.4369e-03, -1.2658e+00],\n",
      "         [-2.6571e+00,  9.8013e+00, -2.2844e+00, -2.5351e+00, -2.5656e+00]],\n",
      "\n",
      "        [[-2.3047e+00,  3.7426e+00, -5.6088e+00, -2.2535e+00,  2.5585e-01],\n",
      "         [-1.1424e+00,  9.4817e-01, -2.3128e+00, -8.3853e-01,  1.1490e+00],\n",
      "         [ 1.0440e+00, -3.1784e+00,  2.6440e+00,  1.9905e+00,  1.7419e+00]],\n",
      "\n",
      "        [[-1.9180e+00,  3.6779e+00, -3.7619e+00, -3.3922e+00, -1.0628e+00],\n",
      "         [-2.1841e-01, -1.5968e-01, -4.3934e-01, -5.1617e-01,  2.1498e-01],\n",
      "         [ 1.3342e-01, -2.8367e-01,  2.2764e-01, -9.9841e-01, -8.2301e-01]]])\n",
      "torch.Size([10, 3, 5]) !!!!!\n"
     ]
    }
   ],
   "source": [
    "# vector x vector: dot product\n",
    "t1 = torch.randn(3)\n",
    "t2 = torch.randn(3)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(torch.matmul(t1, t2))\n",
    "print(torch.matmul(t1, t2).size(), \"!\") \n",
    "\n",
    "# matrix x vector: broadcasted dot\n",
    "t3 = torch.randn(3, 4)\n",
    "t4 = torch.randn(4)\n",
    "print(t3)\n",
    "print(t4)\n",
    "print(torch.matmul(t3, t4))\n",
    "print(torch.matmul(t3, t4).size(), \"!!\") \n",
    "t4 = torch.randn(3)\n",
    "print(t4)\n",
    "print(torch.matmul(t4, t3))\n",
    "print(torch.matmul(t4, t3).size(), \"!!\")\n",
    "\n",
    "# batched matrix x vector: broadcasted dot\n",
    "t5 = torch.randn(10, 3, 4)\n",
    "t6 = torch.randn(4)\n",
    "print(t5)\n",
    "print(t6)\n",
    "print(torch.matmul(t5, t6))\n",
    "print(torch.matmul(t5, t6).size(), \"!!!\")\n",
    "\n",
    "# batched matrix x batched matrix: bmm\n",
    "t7 = torch.randn(10, 3, 4)\n",
    "t8 = torch.randn(10, 4, 5)\n",
    "print(t7)\n",
    "print(t8)\n",
    "print(torch.matmul(t7, t8))\n",
    "print(torch.matmul(t7, t8).size(), \"!!!!\")\n",
    "\n",
    "# batched matrix x matrix: bmm\n",
    "t9 = torch.randn(10, 3, 4)\n",
    "t10 = torch.randn(4, 5)\n",
    "print(t9)\n",
    "print(t10)\n",
    "print(torch.matmul(t9, t10))\n",
    "print(torch.matmul(t9, t10).size(), \"!!!!!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ddb27-a426-473f-9fc3-e3528b1a861c",
   "metadata": {},
   "source": [
    "torch.matmul\n",
    ">두 tensor의 행렬 곱으로 아래와 같이 tensor의 차원에 따라 수행 방식이 달라짐\n",
    ">>모두 1차원일 경우 도트 곱\n",
    ">\n",
    ">\n",
    ">>2차원일 경우 행렬 곱\n",
    ">\n",
    ">\n",
    ">>첫번째 인자 1차원, 두번째 인자 2차원일 경우 첫번째 인자에 1차원이 추가되고 행렬곱셈 후 차원 제거\n",
    ">\n",
    ">\n",
    ">>첫번째 인자 2차원, 두번째 인자 1차원일 경우 broadcasted dot 계산\n",
    ">\n",
    ">\n",
    ">>n차원, n차원 일 경우\n",
    ">>>input(k*n*m), other(k*m*t), out(k*n*t)\n",
    ">>\n",
    ">>\n",
    ">>>input(j*1*n*n), other(k*n*n), out(j*k*n*n)\n",
    ">>\n",
    ">>\n",
    ">>>input(j*1*n*n), other(k*m*p), out(j*k*n*p)\n",
    ">>\n",
    ">>\n",
    ">tor\n",
    "\n",
    ">torch.matmul(input, other, *, out=None)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ff3f8-ea7a-493e-9be2-b4c2aa43df63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a67a3560-3099-4346-806c-686ad01f1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78124019-6aa3-4d03-8e12-e1428f3fefe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1 * t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36426f35-be28-4ff4-8b93-435ac5095b4f",
   "metadata": {},
   "source": [
    "t2의 값을 t1의 broadcasted 해서 곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d79fbd02-c14f-4a1a-93b5-329c7ac9898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4, -4],\n",
      "        [-2, -1],\n",
      "        [ 6,  5]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
    "t4 = torch.tensor([4, 5])\n",
    "print(t3 - t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fae1b9-5279-4200-b578-622ea730c6b5",
   "metadata": {},
   "source": [
    "t4의 값을 t3의 broadcasted해서 차원에 맞춰 요소를 뺌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4032c3b-2172-4566-b3b7-b3e64290abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t5 + 2.0) \n",
    "print(t5 - 2.0) \n",
    "print(t5 * 2.0)  \n",
    "print(t5 / 2.0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462c3b5-826c-48b0-b15a-f4610c1a81f4",
   "metadata": {},
   "source": [
    "각 연산에 맞춰 스칼라 값을 tensor의 broadcasted해서 모든 요소에 연산해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a526b02e-299e-4f83-aa40-149caf60010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1719, -0.2925,  0.3279,  ..., -0.0249, -1.4473,  0.2412],\n",
      "         [ 0.6834, -1.0371, -0.2216,  ..., -0.8588, -0.5963,  1.0098],\n",
      "         [-0.2098,  0.5969,  1.7913,  ..., -0.8927, -0.2805,  0.7293],\n",
      "         ...,\n",
      "         [ 0.0121,  0.8591, -0.2644,  ..., -0.4610,  1.2765,  0.8202],\n",
      "         [ 0.1559,  0.6365,  1.0746,  ..., -0.3005, -0.4773,  0.9754],\n",
      "         [ 1.2047, -0.5631,  2.9064,  ...,  1.5419, -0.0440, -2.9189]],\n",
      "\n",
      "        [[-0.6450, -1.4451, -0.7492,  ...,  0.5988, -0.3920,  1.0211],\n",
      "         [-0.1843, -1.0505, -2.1471,  ..., -0.7087, -0.1565, -0.0987],\n",
      "         [-1.5852,  0.8719,  0.4008,  ...,  0.4100, -0.1276,  1.3463],\n",
      "         ...,\n",
      "         [-2.2456, -0.8266,  1.1859,  ...,  1.0109,  0.4998,  0.4500],\n",
      "         [-1.8382, -1.1656, -0.8066,  ..., -0.7669, -0.2664, -0.8339],\n",
      "         [ 1.0981,  0.9372, -0.8587,  ..., -0.6134, -0.2306, -1.4975]],\n",
      "\n",
      "        [[ 0.4936, -0.1543,  0.3230,  ...,  0.2653, -1.1500,  0.2543],\n",
      "         [ 1.1746,  1.5592,  0.4177,  ...,  1.7500,  2.0408, -1.4967],\n",
      "         [-0.4697, -0.2122,  0.4063,  ..., -0.8784, -1.3714, -0.0808],\n",
      "         ...,\n",
      "         [-0.0153, -0.1092,  0.4020,  ...,  0.0987, -1.7629,  0.3297],\n",
      "         [ 0.0595,  1.4113, -0.5186,  ..., -0.6483, -0.0959,  0.0447],\n",
      "         [ 0.1710, -1.0133, -1.2987,  ...,  0.5689, -0.4152, -0.2074]]])\n",
      "torch.Size([3, 28, 28])\n",
      "tensor([[[ 6.7420e-04, -1.1470e-03,  1.2859e-03,  ..., -9.7752e-05,\n",
      "          -5.6756e-03,  9.4605e-04],\n",
      "         [ 2.6800e-03, -4.0672e-03, -8.6889e-04,  ..., -3.3677e-03,\n",
      "          -2.3384e-03,  3.9600e-03],\n",
      "         [-8.2265e-04,  2.3406e-03,  7.0249e-03,  ..., -3.5008e-03,\n",
      "          -1.0999e-03,  2.8601e-03],\n",
      "         ...,\n",
      "         [ 4.7306e-05,  3.3691e-03, -1.0367e-03,  ..., -1.8079e-03,\n",
      "           5.0057e-03,  3.2167e-03],\n",
      "         [ 6.1135e-04,  2.4959e-03,  4.2139e-03,  ..., -1.1784e-03,\n",
      "          -1.8716e-03,  3.8250e-03],\n",
      "         [ 4.7242e-03, -2.2082e-03,  1.1398e-02,  ...,  6.0466e-03,\n",
      "          -1.7242e-04, -1.1447e-02]],\n",
      "\n",
      "        [[-2.5293e-03, -5.6672e-03, -2.9381e-03,  ...,  2.3481e-03,\n",
      "          -1.5373e-03,  4.0043e-03],\n",
      "         [-7.2285e-04, -4.1194e-03, -8.4199e-03,  ..., -2.7792e-03,\n",
      "          -6.1374e-04, -3.8687e-04],\n",
      "         [-6.2163e-03,  3.4192e-03,  1.5716e-03,  ...,  1.6079e-03,\n",
      "          -5.0038e-04,  5.2795e-03],\n",
      "         ...,\n",
      "         [-8.8064e-03, -3.2416e-03,  4.6505e-03,  ...,  3.9643e-03,\n",
      "           1.9600e-03,  1.7646e-03],\n",
      "         [-7.2087e-03, -4.5711e-03, -3.1630e-03,  ..., -3.0076e-03,\n",
      "          -1.0446e-03, -3.2702e-03],\n",
      "         [ 4.3062e-03,  3.6754e-03, -3.3676e-03,  ..., -2.4055e-03,\n",
      "          -9.0424e-04, -5.8727e-03]],\n",
      "\n",
      "        [[ 1.9358e-03, -6.0509e-04,  1.2666e-03,  ...,  1.0403e-03,\n",
      "          -4.5098e-03,  9.9706e-04],\n",
      "         [ 4.6064e-03,  6.1147e-03,  1.6381e-03,  ...,  6.8626e-03,\n",
      "           8.0033e-03, -5.8695e-03],\n",
      "         [-1.8420e-03, -8.3211e-04,  1.5933e-03,  ..., -3.4449e-03,\n",
      "          -5.3782e-03, -3.1689e-04],\n",
      "         ...,\n",
      "         [-6.0057e-05, -4.2809e-04,  1.5763e-03,  ...,  3.8703e-04,\n",
      "          -6.9134e-03,  1.2930e-03],\n",
      "         [ 2.3318e-04,  5.5344e-03, -2.0338e-03,  ..., -2.5425e-03,\n",
      "          -3.7608e-04,  1.7537e-04],\n",
      "         [ 6.7044e-04, -3.9736e-03, -5.0928e-03,  ...,  2.2308e-03,\n",
      "          -1.6283e-03, -8.1339e-04]]])\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "  return x / 255\n",
    "\n",
    "t6 = torch.randn(3, 28, 28)\n",
    "print(t6)\n",
    "print(normalize(t6).size())\n",
    "print(normalize(t6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e6840-e1ae-4ab8-94ea-4efb784a0b65",
   "metadata": {},
   "source": [
    "함수도 broadcasted 되는 것을 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192a9956-c371-4e6a-9caf-28cd590142d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor([[6, 7],\n",
      "        [2, 5]])\n",
      "tensor([[8, 6],\n",
      "        [5, 3]])\n",
      "tensor([[ 8,  9],\n",
      "        [ 7, 10]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.tensor([[1, 2], [0, 3]]) \n",
    "t8 = torch.tensor([[3, 1]])  \n",
    "t9 = torch.tensor([[5], [2]])  \n",
    "t10 = torch.tensor([7]) \n",
    "print(t7 + t8)  \n",
    "print(t7 + t9)   \n",
    "print(t8 + t9)  \n",
    "print(t7 + t10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b02dbd-e4eb-4125-adb1-0150933ba1d8",
   "metadata": {},
   "source": [
    "broadcasted가 가능하려면 한쪽에 차원이 다른 차원의 배수의 형태이면 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b021524f-6cf5-4c08-bbf0-b3a4d7bd2dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "t11 = torch.ones(4, 3, 2)\n",
    "t12 = t11 * torch.rand(3, 2) \n",
    "print(t12.shape)\n",
    "\n",
    "t13 = torch.ones(4, 3, 2)\n",
    "t14 = t13 * torch.rand(3, 1) \n",
    "print(t14.shape)\n",
    "\n",
    "t15 = torch.ones(4, 3, 2)\n",
    "t16 = t15 * torch.rand(1, 2)  \n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.ones(5, 3, 4, 1)\n",
    "t18 = torch.rand(3, 1, 1)  \n",
    "print((t17 + t18).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9b215-29d6-4413-837a-c117db559b5f",
   "metadata": {},
   "source": [
    "tensor의 차원의 dim이 다르더라도 한쪽에 차원을 추가하여 만들 수 있다면 broadcasted 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4e99ea8-d057-40d7-963e-28e9c188e9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4, 1]) v1\n",
      "torch.Size([5, 3, 4, 2]) v2\n",
      "torch.Size([5, 3, 4, 7]) v3\n",
      "torch.Size([3, 1, 7])\n",
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 = torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size(), \"v1\") \n",
    "\n",
    "t19 = torch.empty(5, 3, 4, 2)\n",
    "t20 = torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size(), \"v2\") \n",
    "\n",
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 = torch.empty(3, 1, 7)\n",
    "print((t19 + t20).size(), \"v3\") \n",
    "\n",
    "# t19 = torch.empty(5, 6, 4, 1)\n",
    "# t20 = torch.empty(3, 1, 7)\n",
    "# print((t19 + t20).size(), \"v4\") \n",
    "\n",
    "t21 = torch.empty(1)\n",
    "t22 = torch.empty(3, 1, 7)\n",
    "print((t21 + t22).size()) \n",
    "\n",
    "t23 = torch.ones(3, 3, 3)\n",
    "t24 = torch.ones(3, 1, 3)\n",
    "print((t23 + t24).size()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1253bdc-2930-4a85-a8aa-ab7582b400b4",
   "metadata": {},
   "source": [
    "broadcasting은 같은 차원의 크기가 한쪽이 1이거나 차원이 동일하여야 가능\n",
    ">v1, v2, v3은 가능하고 v4는 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21909dc2-749b-4b76-9fe3-c4788c9fabca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5., 5., 5.])\n",
      "tensor([25., 25., 25., 25.])\n",
      "tensor([  1.,   4.,  27., 256.])\n"
     ]
    }
   ],
   "source": [
    "t27 = torch.ones(4) * 5\n",
    "print(t27)  # >>> tensor([ 5, 5, 5, 5])\n",
    "\n",
    "t28 = torch.pow(t27, 2)\n",
    "print(t28)  # >>> tensor([ 25, 25, 25, 25])\n",
    "\n",
    "exp = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
    "a = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
    "t29 = torch.pow(a, exp)\n",
    "print(t29)  # >>> tensor([   1.,    4.,   27.,  256.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855abb7a-1d1b-444c-a46e-66e8f288651b",
   "metadata": {},
   "source": [
    "torch.pow(t27, 2)\n",
    ">차원의 크기가 한쪽이 1일 경우\n",
    ">\n",
    ">\n",
    ">>각 요소의 1인 차원의 값 연산 수행\n",
    "\n",
    "torch.pow(a, exp)\n",
    ">차원의 크기가 동일할 경우\n",
    ">\n",
    ">\n",
    ">>각 요소별로 연산 수행\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb22c5-5d7e-4e6f-be42-f27d72b28117",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a63b3246-3dd8-4e9c-94b3-029900597b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e78d0f0-6061-4a0c-a4ba-221ebdf29ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8, 9])\n",
      "tensor([ 1,  6, 11])\n",
      "tensor(7)\n",
      "tensor([ 4,  9, 14])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9],\n",
    "   [10, 11, 12, 13, 14]]\n",
    ")\n",
    "\n",
    "print(x[1])  \n",
    "print(x[:, 1])  \n",
    "print(x[1, 2]) \n",
    "print(x[:, -1]) \n",
    "print(x[1:])\n",
    "print(x[1:, 3:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703eb7b-d3f0-4f82-849b-529106eab9ff",
   "metadata": {},
   "source": [
    "파이썬의 리스트에서 주로 사용되는 슬라이스를 tensor에서도 사용 가능\n",
    "\n",
    "\n",
    ",의 순서대로 좌측부터 dim 0이라고 생각하고 :의 좌측이 시작위치 우측이 종료 위치\n",
    ">:만 사용 될 경우 all\n",
    ">\n",
    ">\n",
    ">우측의 경우 해당 위치까지는 안들어감 -1 위치까지만 적용됨\n",
    ">\n",
    ">\n",
    ">> x:y == [x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92be3c64-fde7-417a-8e80-fbc7523d2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros((6, 6))\n",
    "y[1:4, 2] = 1\n",
    "print(y)\n",
    "\n",
    "print(y[1:4, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ef1147e-6f33-4081-894a-b087dfcf5039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 3, 4, 5]])\n",
      "tensor([[3, 4],\n",
      "        [6, 7]])\n",
      "tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 0, 0, 5],\n",
      "        [5, 0, 0, 8]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.tensor(\n",
    "  [[1, 2, 3, 4],\n",
    "   [2, 3, 4, 5],\n",
    "   [5, 6, 7, 8]]\n",
    ")\n",
    "print(z[:2])\n",
    "print(z[1:, 1:3])\n",
    "print(z[:, 1:])\n",
    "\n",
    "z[1:, 1:3] = 0\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3191e7b-2f5f-439e-9d51-5f947b94557a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5a6774e-890f-47d9-a826-833ee457b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdbc6063-e392-4bcf-be3c-48c92b974d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = t1.view(3, 2)  \n",
    "t3 = t1.reshape(1, 6)  \n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.arange(8).view(2, 4)  \n",
    "t5 = torch.arange(6).view(2, 3) \n",
    "print(t4)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeaa9ba-7a7a-47d8-a42b-625aebff403c",
   "metadata": {},
   "source": [
    "t1.view(3, 2)\n",
    ">self tensor와 데이터는 같지만 shape이 다른 새 텐서 반환\n",
    ">\n",
    ">\n",
    ">데이터를 공유하며 요소 수가 같아야 하지만 크기는 다를 수 있다\n",
    "\n",
    "\n",
    "t1.reshape(1, 6)\n",
    ">self와 데이터 및 요소 수는 동일하지만 지정된 모양을 가진 tensor 반환\n",
    "\n",
    "\n",
    "view와 reshape의 차이\n",
    ">view는 contiguous 속성을 만족하지 못할 경우 일부 사용이 제한됨\n",
    "\n",
    "\n",
    "contiguous\n",
    ">axis 순서대로 자료가 저장된 상태 true\n",
    ">\n",
    ">\n",
    ">자료 저장 순서가 원래 방향과 어극난 경우 false\n",
    "\n",
    "\n",
    "torch.arange(8).view(2, 4)\n",
    ">arange와 view 동시 사용\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4562d2a6-56fc-4b33-8a51-8498ceddd402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with shape (1, 3, 1)\n",
    "t6 = torch.tensor([[[1], [2], [3]]])\n",
    "\n",
    "# Remove all dimensions of size 1\n",
    "t7 = t6.squeeze()  \n",
    "\n",
    "# Remove dimension at position 0\n",
    "t8 = t6.squeeze(0)  \n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf9ee9-6309-41b5-900c-799b1a34e8c9",
   "metadata": {},
   "source": [
    "self.squeeze(dim)\n",
    ">input의 dim의 차원의 크기가 1이면 해당 차원 제거\n",
    ">\n",
    ">\n",
    ">만약 dim이 안주어지면 해당 tensor의 크기가 1인 차원 전부 제거\n",
    "\n",
    "\n",
    "torch.squeeze(input, dim=None, *, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4c241bd-51af-42cd-b3f3-11d9fa9bae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]]) torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with shape (3,)\n",
    "t9 = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Add a new dimension at position 1\n",
    "t10 = t9.unsqueeze(1)  # Shape becomes (3, 1)\n",
    "print(t10)\n",
    "\n",
    "t11 = torch.tensor(\n",
    "  [[1, 2, 3],\n",
    "   [4, 5, 6]]\n",
    ")\n",
    "t12 = t11.unsqueeze(1)  # Shape becomes (2, 1, 3)\n",
    "print(t12, t12.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd52a12-81b2-4d2b-80e2-1f959a7ee52f",
   "metadata": {},
   "source": [
    "self.unsqueeze(dim)\n",
    ">dim의 크기가 1인 차원 추가\n",
    ">\n",
    ">\n",
    ">만약 해당 위치에 이미 차원이 있다면 해당 차원과 해당 차원-1 차원 사이의 차원 추가\n",
    "\n",
    "\n",
    "torch.unsqueeze(input, dim)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c67ec01f-25a9-4e55-b763-2ad7f8c19f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "t13 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Flatten the tensor\n",
    "t14 = t13.flatten()  # Shape becomes (6,)\n",
    "\n",
    "print(t14)\n",
    "\n",
    "# Original tensor with shape (2, 2, 2)\n",
    "t15 = torch.tensor([[[1, 2],\n",
    "                     [3, 4]],\n",
    "                    [[5, 6],\n",
    "                     [7, 8]]])\n",
    "t16 = torch.flatten(t15)\n",
    "\n",
    "t17 = torch.flatten(t15, start_dim=1)\n",
    "\n",
    "print(t16)\n",
    "print(t17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3519d-692e-4d6e-be2c-6282c5fbb372",
   "metadata": {},
   "source": [
    "torch.flatten\n",
    ">input tensor를 1차원 텐서로 재형성\n",
    "\n",
    "\n",
    "torch.flatten(input, start_dim=0, end_dim=-1)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ab8ca3f-3e58-4595-85ab-1883fa0477f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "t18 = torch.randn(2, 3, 5)\n",
    "print(t18.shape)  # >>> torch.Size([2, 3, 5])\n",
    "print(torch.permute(t18, (2, 0, 1)).size())\n",
    "\n",
    "# Original tensor with shape (2, 3)\n",
    "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Permute the dimensions\n",
    "t20 = torch.permute(t19, dims=(0, 1))  # Shape becomes (2, 3) still\n",
    "t21 = torch.permute(t19, dims=(1, 0))  # Shape becomes (3, 2)\n",
    "print(t20)\n",
    "print(t21)\n",
    "\n",
    "# Transpose the tensor\n",
    "t22 = torch.transpose(t19, 0, 1)  # Shape becomes (3, 2)\n",
    "\n",
    "print(t22)\n",
    "\n",
    "t23 = torch.t(t19)  # Shape becomes (3, 2)\n",
    "\n",
    "print(t23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4aa441-9b9f-42d7-8d1b-71ecbad33cd4",
   "metadata": {},
   "source": [
    "torch.permute\n",
    ">tensor의 shape변경 차원의 dim index로 변경\n",
    ">\n",
    ">\n",
    ">동시에 여러개의 차원 변경 가능\n",
    "\n",
    "\n",
    "torch.transpose\n",
    ">input의 전치된 버전인 텐서 반환\n",
    ">\n",
    ">\n",
    ">torch.transpose(input, dim0, dim1)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ed0bc-fb93-4746-8a54-16356d9c2f07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b33009a-e0d3-49b4-af45-08b65929c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54cdcc9c-e638-47ec-a823-48bfbd940048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 6, 3])\n",
      "tensor([[[0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000],\n",
      "         [0.4833, 0.1801, 0.3354],\n",
      "         [0.9461, 0.1084, 0.3837]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000],\n",
      "         [0.8157, 0.4421, 0.0204],\n",
      "         [0.8765, 0.0451, 0.7221]]])\n",
      "torch.Size([2, 6, 3])\n",
      "torch.Size([8])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.zeros([2, 3, 3])\n",
    "t3 = torch.zeros([2, 2, 3])\n",
    "\n",
    "t4 = torch.cat([t1, t2, t3], dim=1)\n",
    "print(t4)\n",
    "print(t4.shape)\n",
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.ones([2, 3, 3])\n",
    "t3 = torch.rand([2, 2, 3])\n",
    "\n",
    "t4 = torch.cat([t1, t2, t3], dim=1)\n",
    "print(t4)\n",
    "print(t4.shape)\n",
    "\n",
    "t5 = torch.arange(0, 3)  \n",
    "t6 = torch.arange(3, 8)  \n",
    "\n",
    "t7 = torch.cat((t5, t6), dim=0)\n",
    "print(t7.shape)  \n",
    "print(t7)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb224c0e-cd3d-4ee8-b9d7-b0945c9177b2",
   "metadata": {},
   "source": [
    "torch.cat\n",
    ">주어진 차원을 연결\n",
    ">\n",
    ">\n",
    ">모든 텐서는 동일한 모양이거나 비어 있어야 함\n",
    ">\n",
    ">\n",
    ">torch.cat(tensors, dim=0, *, out=None)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e05d48b-18de-48ae-a993-3b6b31cced53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([2, 6])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "t8 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t9 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "# 2차원 텐서간 병합\n",
    "t10 = torch.cat((t8, t9), dim=0)\n",
    "print(t10.size())  # >>> torch.Size([4, 3])\n",
    "print(t10)\n",
    "# >>> tensor([[ 0,  1,  2],\n",
    "#             [ 3,  4,  5],\n",
    "#             [ 6,  7,  8],\n",
    "#             [ 9, 10, 11]])\n",
    "\n",
    "t11 = torch.cat((t8, t9), dim=1)\n",
    "print(t11.size())  # >>>torch.Size([2, 6])\n",
    "print(t11)\n",
    "# >>> tensor([[ 0,  1,  2,  6,  7,  8],\n",
    "#             [ 3,  4,  5,  9, 10, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b4b230d-c674-48dc-8238-71dd3c6ee1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "torch.Size([2, 9])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
      "        [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "t12 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t13 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t14 = torch.arange(12, 18).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "t15 = torch.cat((t12, t13, t14), dim=0)\n",
    "print(t15.size())  # >>> torch.Size([6, 3])\n",
    "print(t15)\n",
    "# >>> tensor([[ 0,  1,  2],\n",
    "#             [ 3,  4,  5],\n",
    "#             [ 6,  7,  8],\n",
    "#             [ 9, 10, 11],\n",
    "#             [12, 13, 14],\n",
    "#             [15, 16, 17]])\n",
    "\n",
    "t16 = torch.cat((t12, t13, t14), dim=1)\n",
    "print(t16.size())  # >>> torch.Size([2, 9])\n",
    "print(t16)\n",
    "# >>> tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
    "#             [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1237f8a5-4f46-43c6-a661-5a8e7ca70392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 2, 6])\n",
      "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
      "         [ 3,  4,  5,  9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "t17 = torch.arange(0, 6).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "t18 = torch.arange(6, 12).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "\n",
    "t19 = torch.cat((t17, t18), dim=0)\n",
    "print(t19.size())  # >>> torch.Size([2, 2, 3])\n",
    "print(t19)\n",
    "# >>> tensor([[[ 0,  1,  2],\n",
    "#              [ 3,  4,  5]],\n",
    "#             [[ 6,  7,  8],\n",
    "#              [ 9, 10, 11]]])\n",
    "\n",
    "t20 = torch.cat((t17, t18), dim=1)\n",
    "print(t20.size())  # >>> torch.Size([1, 4, 3])\n",
    "print(t20)\n",
    "# >>> tensor([[[ 0,  1,  2],\n",
    "#              [ 3,  4,  5],\n",
    "#              [ 6,  7,  8],\n",
    "#              [ 9, 10, 11]]])\n",
    "\n",
    "t21 = torch.cat((t17, t18), dim=2)\n",
    "print(t21.size())  # >>> torch.Size([1, 2, 6])\n",
    "print(t21)\n",
    "# >>> tensor([[[ 0,  1,  2,  6,  7,  8],\n",
    "#              [ 3,  4,  5,  9, 10, 11]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195881ae-16e9-451e-b568-d37208e4f320",
   "metadata": {},
   "source": [
    "차원을 합칠 때 tensor의 입력순으로 요소를 채우며 해당 차원의 크기를 더하고 tensor를 구성한다고 생각하면 쉽게 할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d271e-ba25-4cc3-b43b-5eb5fe10f59a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f285691d-7040-4ede-98ea-5df9970a09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d9182ec-8441-4bf6-9e66-2dc95a1da7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 3, 2]) True\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "t3 = torch.stack([t1, t2], dim=0)\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0)\n",
    "print(t3.shape, t3.equal(t4))\n",
    "\n",
    "t5 = torch.stack([t1, t2], dim=1)\n",
    "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1)\n",
    "print(t5.shape, t5.equal(t6))\n",
    "\n",
    "t7 = torch.stack([t1, t2], dim=2)\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2)\n",
    "print(t7.shape, t7.equal(t8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16985eb7-b41a-4f44-9b7c-7c55305c6633",
   "metadata": {},
   "source": [
    "torch.stack\n",
    ">새로운 차원을 따라 tensor 연결\n",
    ">\n",
    ">\n",
    ">모든 텐서의 크기는 동일해야 함\n",
    ">\n",
    ">\n",
    ">torch.stack(tensors, dim=0, *, out=None)\n",
    "\n",
    "\n",
    "self.equal\n",
    ">self와 input의 tensor가 동일한지 확인\n",
    ">\n",
    ">\n",
    ">torch.equal(input, other)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "970fc70f-7525-4849-be4e-17e06586525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "True\n",
      "torch.Size([3, 2])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t10 = torch.arange(3, 6)  # tensor([3, 4, 5])\n",
    "\n",
    "print(t9.size(), t10.size())\n",
    "# >>> torch.Size([3]) torch.Size([3])\n",
    "\n",
    "t11 = torch.stack((t9, t10), dim=0)\n",
    "print(t11.size())  # >>> torch.Size([2,3])\n",
    "print(t11)\n",
    "# >>> tensor([[0, 1, 2],\n",
    "#             [3, 4, 5]])\n",
    "\n",
    "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0)\n",
    "print(t11.equal(t12))\n",
    "# >>> True\n",
    "\n",
    "t13 = torch.stack((t9, t10), dim=1)\n",
    "print(t13.size())  # >>> torch.Size([3,2])\n",
    "print(t13)\n",
    "# >>> tensor([[0, 3],\n",
    "#             [1, 4],\n",
    "#             [2, 5]])\n",
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1)\n",
    "print(t13.equal(t14))\n",
    "# >>> True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df4ba9-fa70-44e4-b609-8ba62d9ccad4",
   "metadata": {},
   "source": [
    "stack으로 합치는 과정을 cat 및 해당 차원을 unsqueeze로 증가시켜 동일하게 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422fa87-68ea-47bd-899e-12d6a88d01bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8804bc84-8192-4775-b278-38687ea26dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81fbacbc-f3e8-4194-a3e7-de0f993b54ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([6, 1])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([4, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "t3 = torch.vstack((t1, t2))\n",
    "print(t1.shape)\n",
    "print(t2.shape)\n",
    "print(t3.shape)\n",
    "print(t3)\n",
    "\n",
    "\n",
    "t4 = torch.tensor([[1], [2], [3]])\n",
    "t5 = torch.tensor([[4], [5], [6]])\n",
    "t6 = torch.vstack((t4, t5))\n",
    "print(t4.shape)\n",
    "print(t5.shape)\n",
    "print(t6.shape)\n",
    "print(t6)\n",
    "\n",
    "t7 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t7.shape)\n",
    "\n",
    "\n",
    "t8 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t8.shape)\n",
    "\n",
    "\n",
    "t9 = torch.vstack([t7, t8])\n",
    "print(t9.shape)\n",
    "\n",
    "\n",
    "print(t9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963164dc-11b8-4d36-aaf6-30702162d40a",
   "metadata": {},
   "source": [
    "torch.vstack\n",
    ">tensor를 세로로 순서대로 쌓음\n",
    ">\n",
    ">\n",
    ">dim 0이 합쳐진다 생각, 만약 둘다 1차원일 경우 새로운 차원으로 합쳐짐 (t1, t2, t3)\n",
    ">\n",
    ">\n",
    ">torch.vstack(tensors, *, out=None)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0e163ad-77cb-49dd-bed0-7a0d6bf63500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12],\n",
      "         [19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "t10 = torch.tensor([1, 2, 3])\n",
    "t11 = torch.tensor([4, 5, 6])\n",
    "t12 = torch.hstack((t10, t11))\n",
    "print(t12)\n",
    "\n",
    "t13 = torch.tensor([[1], [2], [3]])\n",
    "t14 = torch.tensor([[4], [5], [6]])\n",
    "t15 = torch.hstack((t13, t14))\n",
    "print(t15)\n",
    "\n",
    "t16 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t17.shape)\n",
    "\n",
    "t18 = torch.hstack([t16, t17])\n",
    "print(t18.shape)\n",
    "\n",
    "print(t18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560bbd8-c47e-40ac-b87a-003aef426af3",
   "metadata": {},
   "source": [
    "torch.hstack\n",
    ">tensor를 가로 방향으로 순서대로 쌓음\n",
    ">\n",
    ">\n",
    ">1차원 tensor의 경우 dim 0으로 연결하고 다른 모든 tensor는 dim 1 축으로 연결\n",
    ">\n",
    ">\n",
    ">torch.hstack(tensors, *, out=None)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4847aa-047e-4795-8ad6-b75d309abf89",
   "metadata": {},
   "source": [
    "# 숙제 후기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d797149-fb17-460f-920a-0eb1153dead5",
   "metadata": {},
   "source": [
    "tensor에 대해서 처음 배워보는 내용이라 걱정도 많았지만 새로운 것을 배운다는 것이 설레어 재미있게 진행하였다. tensor의 여러가지 함수들을 직접 사용해보며 각 사용법을 알게 되었고 내부적으로 어떤식으로 동작하는지 궁금하여 함수의 원형과 함께 여러자료들을 찾아보게 되었다.\n",
    "지금 공부해본 내용도 많다고 생각되었는데 tensor와 관련된 라이브러리 함수들에 목록을 보며 배울것이 많이 남아 걱정이 많이 되었다.\n",
    "수업 진행도 처음 배워보는 내용이라 걱정을 많이 하였는데 교수님께서 천천히 설명 해주시며 실제 계산하는 방식을 보여주시며 수업을 하셔서 이해가 잘 되었습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
